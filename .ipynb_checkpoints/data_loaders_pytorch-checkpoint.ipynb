{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d8cfa51-8df3-407b-9efc-baa747058b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np \n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28988fe8-f7ba-498f-a1ea-472c7517cea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.846e+01, 3.420e+00, 4.860e+00, 3.120e+01, 2.540e+02, 5.600e+00,\n",
       "        6.120e+00, 5.600e-01, 4.580e+00, 1.128e+01, 2.080e+00, 7.840e+00,\n",
       "        2.130e+03], dtype=float32),\n",
       " array([1.], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('../datasets/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:,1:]  #torch.from_numpy(xy[:,1:])\n",
    "        self.y = xy[:,[0]]  #torch.from_numpy(xy[:,[0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample =  self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "                self.transform(sample)\n",
    "        return sample \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class ToTensor():\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        \n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "    \n",
    "\n",
    "class MulTranform():\n",
    "    \n",
    "    def __init__(self, factor=2):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample[:]\n",
    "        \n",
    "        inputs *= self.factor\n",
    "        \n",
    "        return inputs, targets \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "transform = torchvision.transforms.Compose([MulTranform(), ToTensor()])\n",
    "\n",
    "dataset = WineDataset(transform=transform)\n",
    "\n",
    "\n",
    "first_data = dataset[0]\n",
    "\n",
    "features, labels = first_data\n",
    "#DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4388564-d19c-428d-95d4-2f15e65efa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.84599991e+01, 3.42000008e+00, 4.86000013e+00, 3.12000008e+01,\n",
       "       2.54000000e+02, 5.59999990e+00, 6.11999989e+00, 5.60000002e-01,\n",
       "       4.57999992e+00, 1.12799997e+01, 2.07999992e+00, 7.84000015e+00,\n",
       "       2.13000000e+03])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = WineDataset()\n",
    "values[0][0].dot(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f0b9079-fc01-416b-810c-5ffe2f7af3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.0840), tensor(0.2908))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "true = torch.tensor([2,0,1])\n",
    "\n",
    "good_pred = torch.tensor([[0.1, 1, 2.1], [2.1,1,0.1], [0.1, 3, 0.1]])\n",
    "bad_pred = torch.tensor([[2.1,1,0.1], [0.1, 1, 2.1], [0.1, 1, 2.1]])\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_for_good_pred = loss(good_pred, true)\n",
    "loss_for_bad_pred = loss(bad_pred, true)\n",
    "\n",
    "loss_for_bad_pred, loss_for_good_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aebb1e2e-bd1d-4e05-a128-13af0deb028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "This criterion computes the cross entropy loss between input and target.\n",
       "\n",
       "It is useful when training a classification problem with `C` classes.\n",
       "If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
       "assigning weight to each of the classes.\n",
       "This is particularly useful when you have an unbalanced training set.\n",
       "\n",
       "The `input` is expected to contain raw, unnormalized scores for each class.\n",
       "`input` has to be a Tensor of size :math:`(C)` for unbatched input,\n",
       ":math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n",
       "`K`-dimensional case. The last being useful for higher dimension inputs, such\n",
       "as computing cross entropy loss per-pixel for 2D images.\n",
       "\n",
       "The `target` that this criterion expects should contain either:\n",
       "\n",
       "- Class indices in the range :math:`[0, C)` where :math:`C` is the number of classes; if\n",
       "  `ignore_index` is specified, this loss also accepts this class index (this index\n",
       "  may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n",
       "  set to ``'none'``) loss for this case can be described as:\n",
       "\n",
       "  .. math::\n",
       "      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
       "      l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
       "      \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
       "\n",
       "  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
       "  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
       "  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
       "  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
       "\n",
       "  .. math::\n",
       "      \\ell(x, y) = \\begin{cases}\n",
       "          \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n",
       "           \\text{if reduction} = \\text{`mean';}\\\\\n",
       "            \\sum_{n=1}^N l_n,  &\n",
       "            \\text{if reduction} = \\text{`sum'.}\n",
       "        \\end{cases}\n",
       "\n",
       "  Note that this case is equivalent to the combination of :class:`~torch.nn.LogSoftmax` and\n",
       "  :class:`~torch.nn.NLLLoss`.\n",
       "\n",
       "- Probabilities for each class; useful when labels beyond a single class per minibatch item\n",
       "  are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n",
       "  :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n",
       "\n",
       "  .. math::\n",
       "      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
       "      l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\sum_{i=1}^C \\exp(x_{n,i})} y_{n,c}\n",
       "\n",
       "  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
       "  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
       "  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
       "  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
       "\n",
       "  .. math::\n",
       "      \\ell(x, y) = \\begin{cases}\n",
       "          \\frac{\\sum_{n=1}^N l_n}{N}, &\n",
       "           \\text{if reduction} = \\text{`mean';}\\\\\n",
       "            \\sum_{n=1}^N l_n,  &\n",
       "            \\text{if reduction} = \\text{`sum'.}\n",
       "        \\end{cases}\n",
       "\n",
       ".. note::\n",
       "    The performance of this criterion is generally better when `target` contains class\n",
       "    indices, as this allows for optimized computation. Consider providing `target` as\n",
       "    class probabilities only when a single class label per minibatch item is too restrictive.\n",
       "\n",
       "Args:\n",
       "    weight (Tensor, optional): a manual rescaling weight given to each class.\n",
       "        If given, has to be a Tensor of size `C`\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when :attr:`reduce` is ``False``. Default: ``True``\n",
       "    ignore_index (int, optional): Specifies a target value that is ignored\n",
       "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
       "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
       "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
       "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
       "        be applied, ``'mean'``: the weighted mean of the output is taken,\n",
       "        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
       "        and :attr:`reduce` are in the process of being deprecated, and in\n",
       "        the meantime, specifying either of those two args will override\n",
       "        :attr:`reduction`. Default: ``'mean'``\n",
       "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
       "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
       "        become a mixture of the original ground truth and a uniform distribution as described in\n",
       "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
       "\n",
       "Shape:\n",
       "    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
       "      in the case of `K`-dimensional loss.\n",
       "    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n",
       "      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n",
       "      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n",
       "    - Output: If reduction is 'none', same shape as the target. Otherwise, scalar.\n",
       "\n",
       "    where:\n",
       "\n",
       "    .. math::\n",
       "        \\begin{aligned}\n",
       "            C ={} & \\text{number of classes} \\\\\n",
       "            N ={} & \\text{batch size} \\\\\n",
       "        \\end{aligned}\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> # Example of target with class indices\n",
       "    >>> loss = nn.CrossEntropyLoss()\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
       "    >>> output = loss(input, target)\n",
       "    >>> output.backward()\n",
       "    >>>\n",
       "    >>> # Example of target with class probabilities\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
       "    >>> output = loss(input, target)\n",
       "    >>> output.backward()\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/lib/python3.10/site-packages/torch/nn/modules/loss.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NeuralNN():\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \n",
    "        super(NeuralNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activate_fun = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.activate_fun(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e84cd77-b501-4fd6-a77e-05ac4766618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2, step: 1/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 6/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 11/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 16/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 21/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 26/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 31/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 36/45, inputs torch.Size([4, 13]) \n",
      "epoch: 1/2, step: 41/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 1/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 6/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 11/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 16/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 21/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 26/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 31/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 36/45, inputs torch.Size([4, 13]) \n",
      "epoch: 2/2, step: 41/45, inputs torch.Size([4, 13]) \n"
     ]
    }
   ],
   "source": [
    "num_epoch = 2\n",
    "\n",
    "total_samples = len(dataset)\n",
    "\n",
    "n_iteration = math.ceil(total_samples/4)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\n",
    "        if i% 5 == 0:\n",
    "            print(f'epoch: {epoch+1}/{num_epoch}, step: {i+1}/{n_iteration}, inputs {inputs.shape} ')\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e360a-74c0-4a6b-be56-c2ea5a8b6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
